{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import tokenizers\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import typing, os, string, gc, time\n",
    "from nltk.corpus import indian\n",
    "import nltk\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, AdamW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 3.0.2\n",
      "Tokenizers version: 0.8.1.rc1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "print(f\"Tokenizers version: {tokenizers.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(path):\n",
    "    \n",
    "    df = pd.read_csv(path, sep='\\t', encoding='utf-8', header=None)\n",
    "    df.columns = ['label_text', 'text']\n",
    "    df.label_text = pd.Categorical(df.label_text)\n",
    "    df['label'] = df.label_text.cat.codes\n",
    "    #print(df.label_text.cat.categories)\n",
    "    print(f\"Number of examples: {len(df)}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 3468\n",
      "Number of examples: 867\n"
     ]
    }
   ],
   "source": [
    "train_df = process_dataframe('bbc-hindi/hindi-train.csv')\n",
    "valid_df = process_dataframe('bbc-hindi/hindi-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>india</td>\n",
       "      <td>मेट्रो की इस लाइन के चलने से दक्षिणी दिल्ली से...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pakistan</td>\n",
       "      <td>नेटिजन यानि इंटरनेट पर सक्रिय नागरिक अब ट्विटर...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news</td>\n",
       "      <td>इसमें एक फ़्लाइट एटेनडेंट की मदद की गुहार है औ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>india</td>\n",
       "      <td>प्रतीक खुलेपन का, आज़ाद ख्याली का और भीड़ से अ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>india</td>\n",
       "      <td>ख़ासकर पिछले 10 साल तक प्रधानमंत्री रहे मनमोहन...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label_text                                               text  label\n",
       "0      india  मेट्रो की इस लाइन के चलने से दक्षिणी दिल्ली से...      3\n",
       "1   pakistan  नेटिजन यानि इंटरनेट पर सक्रिय नागरिक अब ट्विटर...      9\n",
       "2       news  इसमें एक फ़्लाइट एटेनडेंट की मदद की गुहार है औ...      8\n",
       "3      india  प्रतीक खुलेपन का, आज़ाद ख्याली का और भीड़ से अ...      3\n",
       "4      india  ख़ासकर पिछले 10 साल तक प्रधानमंत्री रहे मनमोहन...      3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_text</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>india</td>\n",
       "      <td>बुधवार को राज्य सभा में विपक्ष के सवालों के जव...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>india</td>\n",
       "      <td>लखनऊ स्थित पत्रकार समीरात्मज मिश्र को बुलंदशहर...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>india</td>\n",
       "      <td>लगभग 1300 हेक्टेयर ज़मीन का अधिग्रहण किया जा च...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>international</td>\n",
       "      <td>हालांकि उनके अंगरक्षकों को बमों को जाम करने वा...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>india</td>\n",
       "      <td>आयोग का कहना है कि इस तरह के परीक्षण से महिलाओ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label_text                                               text  label\n",
       "0          india  बुधवार को राज्य सभा में विपक्ष के सवालों के जव...      3\n",
       "1          india  लखनऊ स्थित पत्रकार समीरात्मज मिश्र को बुलंदशहर...      3\n",
       "2          india  लगभग 1300 हेक्टेयर ज़मीन का अधिग्रहण किया जा च...      3\n",
       "3  international  हालांकि उनके अंगरक्षकों को बमों को जाम करने वा...      5\n",
       "4          india  आयोग का कहना है कि इस तरह के परीक्षण से महिलाओ...      3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBCHindiDataset:\n",
    "    \n",
    "    def __init__(self, data, tokenizer, base_model_type, batch_size):\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.base_model_type = base_model_type\n",
    "        self.batch_size = batch_size\n",
    "        data = [data[i: i+batch_size] for i in range(0, len(data), batch_size)]\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \n",
    "        \n",
    "        for batch in self.data:\n",
    "            \n",
    "            batch = batch.dropna()\n",
    "            texts = list(batch.text)\n",
    "            labels = list(batch.label)\n",
    "            \n",
    "            encoded_input = self.tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "            input_ids = encoded_input['input_ids']\n",
    "            attention_mask = encoded_input['attention_mask']\n",
    "            label = torch.tensor(labels, dtype=torch.long)\n",
    "            if self.base_model_type == 'bert':\n",
    "                token_type_ids = encoded_input['token_type_ids']\n",
    "                yield {\n",
    "                    'input_ids':input_ids,\n",
    "                    'attention_mask':attention_mask,\n",
    "                    'token_type_ids':token_type_ids,\n",
    "                    'label':label\n",
    "                }\n",
    "            else:\n",
    "                \n",
    "                yield {\n",
    "                    'input_ids':input_ids,\n",
    "                    'attention_mask':attention_mask,\n",
    "                    'label':label\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('hi-lm-distilbert/')\n",
    "train_dataset = BBCHindiDataset(train_df, tokenizer, 'bert', 32)\n",
    "valid_dataset = BBCHindiDataset(valid_df, tokenizer, 'bert', 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(valid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "base_model = AutoModel.from_pretrained('hi-lm-distilbert/').to(device)\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoBERTaTextClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, base_model):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.base_model = base_model\n",
    "        self.fc1 = nn.Linear(768, 100)\n",
    "        self.fc2 = nn.Linear(100, 14)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            sequence_output = self.base_model(input_ids, attention_mask)[0]\n",
    "        \n",
    "        # sequence_output = [batch_size, seq_len, 768]\n",
    "        \n",
    "        mean_output = sequence_output.mean(dim=1)\n",
    "        # [bs, 768]\n",
    "        \n",
    "        out = self.fc2(self.fc1(mean_output))\n",
    "        # out = [bs, 14]\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RoBERTaTextClassifier(base_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_dataset):\n",
    "    \n",
    "    print(\"Starting Training\")\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    model.train()\n",
    "    \n",
    "    for bi, batch in enumerate(train_dataset):\n",
    "\n",
    "        if bi % 20 == 0:\n",
    "            print(f\"Starting batch: {bi}\")\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        preds = model(input_ids, attention_mask)\n",
    "        loss = F.cross_entropy(preds, labels)\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_acc += (torch.argmax(preds,dim=1)==labels).float().mean().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    return train_loss/len(train_dataset), train_acc/len(train_dataset)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, valid_dataset):\n",
    "    \n",
    "    print(\"Starting validation\")\n",
    "    valid_loss = 0.\n",
    "    valid_acc = 0.\n",
    "    model.eval()\n",
    "    \n",
    "    for bi, batch in enumerate(valid_dataset):\n",
    "\n",
    "        if bi % 20 == 0:\n",
    "            print(f\"Starting batch: {bi}\")\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            preds = model(input_ids, attention_mask)\n",
    "            loss = F.cross_entropy(preds, labels)\n",
    "        \n",
    "            valid_loss += loss.item()\n",
    "            valid_acc += (torch.argmax(preds,dim=1)==labels).float().mean().item()\n",
    "        \n",
    "        \n",
    "    return valid_loss/len(valid_dataset), valid_acc/len(valid_dataset)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    '''\n",
    "    Helper function to record epoch time.\n",
    "    '''\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Starting Training\n",
      "Starting batch: 0\n",
      "Starting batch: 20\n",
      "Starting batch: 40\n",
      "Starting batch: 60\n",
      "Starting batch: 80\n",
      "Starting batch: 100\n",
      "Starting validation\n",
      "Starting batch: 0\n",
      "Starting batch: 20\n",
      "Epoch train loss : 1.3605404337611766| Time: 5m 11s\n",
      "Epoch valid loss: 1.014705736722265\n",
      "Epoch train accuracy: 0.5916413878082135\n",
      "Epoch valid accuracy: 0.6975566425493785\n",
      "====================================================================================\n",
      "Epoch 2\n",
      "Starting Training\n",
      "Starting batch: 0\n",
      "Starting batch: 20\n",
      "Starting batch: 40\n",
      "Starting batch: 60\n",
      "Starting batch: 80\n",
      "Starting batch: 100\n",
      "Starting validation\n",
      "Starting batch: 0\n",
      "Starting batch: 20\n",
      "Epoch train loss : 0.8979853246736964| Time: 6m 2s\n",
      "Epoch valid loss: 0.8425668829253742\n",
      "Epoch train accuracy: 0.7340436025497017\n",
      "Epoch valid accuracy: 0.7519081213644573\n",
      "====================================================================================\n",
      "Epoch 3\n",
      "Starting Training\n",
      "Starting batch: 0\n",
      "Starting batch: 20\n",
      "Starting batch: 40\n",
      "Starting batch: 60\n",
      "Starting batch: 80\n",
      "Starting batch: 100\n",
      "Starting validation\n",
      "Starting batch: 0\n",
      "Starting batch: 20\n",
      "Epoch train loss : 0.7756573757447234| Time: 6m 16s\n",
      "Epoch valid loss: 0.7782609228576932\n",
      "Epoch train accuracy: 0.7607156951493079\n",
      "Epoch valid accuracy: 0.7854262675557818\n",
      "====================================================================================\n",
      "Epoch 4\n",
      "Starting Training\n",
      "Starting batch: 0\n",
      "Starting batch: 20\n",
      "Starting batch: 40\n",
      "Starting batch: 60\n",
      "Starting batch: 80\n",
      "Starting batch: 100\n",
      "Starting validation\n",
      "Starting batch: 0\n",
      "Starting batch: 20\n",
      "Epoch train loss : 0.7183720737422278| Time: 6m 28s\n",
      "Epoch valid loss: 0.7466984188982418\n",
      "Epoch train accuracy: 0.771619439125061\n",
      "Epoch valid accuracy: 0.7966229830469403\n",
      "====================================================================================\n",
      "Epoch 5\n",
      "Starting Training\n",
      "Starting batch: 0\n",
      "Starting batch: 20\n",
      "Starting batch: 40\n",
      "Starting batch: 60\n",
      "Starting batch: 80\n",
      "Starting batch: 100\n",
      "Starting validation\n",
      "Starting batch: 0\n",
      "Starting batch: 20\n",
      "Epoch train loss : 0.6788996627571386| Time: 6m 8s\n",
      "Epoch valid loss: 0.7305133981364114\n",
      "Epoch train accuracy: 0.7810896963154504\n",
      "Epoch valid accuracy: 0.788774481841496\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "valid_losses = []\n",
    "valid_accs = []\n",
    "train_accs = []\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, optimizer, train_dataset)\n",
    "    valid_loss, valid_acc = validate(model, valid_dataset)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_accs.append(valid_acc)\n",
    "    train_accs.append(train_acc)\n",
    "    \n",
    "    print(f\"Epoch train loss : {train_loss}| Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(f\"Epoch valid loss: {valid_loss}\")\n",
    "    print(f\"Epoch train accuracy: {train_acc}\")\n",
    "    print(f\"Epoch valid accuracy: {valid_acc}\")\n",
    "    print(\"====================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
