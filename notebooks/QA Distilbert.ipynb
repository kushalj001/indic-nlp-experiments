{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, typing, gc, os, sys,string\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "import simpletransformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from simpletransformers.question_answering import QuestionAnsweringModel, QuestionAnsweringArgs\n",
    "import tokenizers\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpletransformers_qa():\n",
    "    \n",
    "    with open('MLQA_V1/test/test-context-hi-question-hi.json','r',encoding='utf-8') as f:\n",
    "        dataset = json.load(f)\n",
    "    data = dataset['data']\n",
    "\n",
    "    mlqa_test = []\n",
    "    for para in data:\n",
    "        paras = para['paragraphs']\n",
    "        for i in range(len(paras)):\n",
    "            mlqa_test.append(paras[i])\n",
    "\n",
    "\n",
    "    model_args = QuestionAnsweringArgs()\n",
    "    model_args.fp16 = False\n",
    "    model_args.train_custom_parameters_only = False\n",
    "    model_args.warmup_steps = 3\n",
    "    model_args.overwrite_output_dir = True\n",
    "    model = QuestionAnsweringModel('distilbert', 'hi-lm-distilbert/',args=model_args)\n",
    "    model.train_model(mlqa_test[:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    '''\n",
    "    Loads the JSON file of the Squad dataset.\n",
    "    Returns the json object of the dataset.\n",
    "    '''\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    print(\"Length of data: \", len(data['data']))\n",
    "    print(\"Data Keys: \", data['data'][0].keys())\n",
    "    print(\"Title: \", data['data'][0]['title'])\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def parse_data(data:dict)->list:\n",
    "    '''\n",
    "    Parses the JSON file of Squad dataset by looping through the\n",
    "    keys and values and returns a list of dictionaries with\n",
    "    context, query and label triplets being the keys of each dict.\n",
    "    '''\n",
    "    data = data['data']\n",
    "    qa_list = []\n",
    "\n",
    "    for paragraphs in data:\n",
    "\n",
    "        for para in paragraphs['paragraphs']:\n",
    "            context = para['context']\n",
    "\n",
    "            for qa in para['qas']:\n",
    "                \n",
    "                id = qa['id']\n",
    "                question = qa['question']\n",
    "                \n",
    "                for ans in qa['answers']:\n",
    "                    answer = ans['text']\n",
    "                    ans_start = ans['answer_start']\n",
    "                    ans_end = ans_start + len(answer)\n",
    "                    \n",
    "                    qa_dict = {}\n",
    "                    qa_dict['id'] = id\n",
    "                    qa_dict['context'] = context\n",
    "                    qa_dict['question'] = question\n",
    "                    qa_dict['label'] = [ans_start, ans_end]\n",
    "\n",
    "                    qa_dict['answer'] = answer\n",
    "                    qa_list.append(qa_dict)    \n",
    "\n",
    "    return qa_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data:  2038\n",
      "Data Keys:  dict_keys(['title', 'paragraphs'])\n",
      "Title:  एरिया 51\n",
      "Length of data:  217\n",
      "Data Keys:  dict_keys(['title', 'paragraphs'])\n",
      "Title:  संयंत्र सेल\n",
      "Length of data:  48\n",
      "Data Keys:  dict_keys(['paragraphs', 'title'])\n",
      "Title:  Super_Bowl_50\n",
      "6615\n"
     ]
    }
   ],
   "source": [
    "mlqa_test_data = load_json('MLQA_V1/test/test-context-hi-question-hi.json')\n",
    "mlqa_dev_data = load_json('MLQA_V1/dev/dev-context-hi-question-hi.json')\n",
    "xsquad_data = load_json('xsquad-hi.json')\n",
    "\n",
    "qa_list = parse_data(mlqa_test_data) + parse_data(mlqa_dev_data) + parse_data(xsquad_data)\n",
    "print(len(qa_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(qa_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eeb8dbd25efe5221dc6723ddee95daa07d2c8478</td>\n",
       "      <td>उसी \"एरिया XX \" नामकरण प्रणाली का प्रयोग नेवाद...</td>\n",
       "      <td>झील के सापेक्ष ग्रूम लेक रोड कहाँ जाती थी?</td>\n",
       "      <td>[378, 389]</td>\n",
       "      <td>उत्तर पूर्व</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ba7865d50777f2b90ba88fcb070a672d042b6b69</td>\n",
       "      <td>में खानों की ओर जाती थीं, लेकिन उनके बंद होने ...</td>\n",
       "      <td>किस प्रकार की सड़कें बड़े खेतों और पशु-फार्मों त...</td>\n",
       "      <td>[308, 316]</td>\n",
       "      <td>डर्ट-रोड</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2079cf7ce47961738e4bd0d527d0b1058210f869</td>\n",
       "      <td>विश्व युद्ध II के दौरान ग्रूम झील का प्रयोग बम...</td>\n",
       "      <td>विमान के लिए परीक्षण पट्टी क्या बनी?</td>\n",
       "      <td>[237, 247]</td>\n",
       "      <td>झील की सतह</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d5377da63e6f64dae5e269290a6334c2a912cb3f</td>\n",
       "      <td>लॉकहीड ने इस स्थल पर एक अस्थायी अड्डे का निर्म...</td>\n",
       "      <td>प्रारंभिक u-2 वितरण के साथ कौन था?</td>\n",
       "      <td>[330, 347]</td>\n",
       "      <td>लॉकहीड विशेषज्ञों</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03df1f92420416844575cfa201ae840319c40650</td>\n",
       "      <td>अधिकांश नेल्लिस सीमा के विपरीत, झील के आस-पास ...</td>\n",
       "      <td>प्रतिबंधित क्षेत्रों में भटकते पर सैन्य पायलटो...</td>\n",
       "      <td>[366, 378]</td>\n",
       "      <td>अनुशासनात्मक</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0  eeb8dbd25efe5221dc6723ddee95daa07d2c8478   \n",
       "1  ba7865d50777f2b90ba88fcb070a672d042b6b69   \n",
       "2  2079cf7ce47961738e4bd0d527d0b1058210f869   \n",
       "3  d5377da63e6f64dae5e269290a6334c2a912cb3f   \n",
       "4  03df1f92420416844575cfa201ae840319c40650   \n",
       "\n",
       "                                             context  \\\n",
       "0  उसी \"एरिया XX \" नामकरण प्रणाली का प्रयोग नेवाद...   \n",
       "1  में खानों की ओर जाती थीं, लेकिन उनके बंद होने ...   \n",
       "2  विश्व युद्ध II के दौरान ग्रूम झील का प्रयोग बम...   \n",
       "3  लॉकहीड ने इस स्थल पर एक अस्थायी अड्डे का निर्म...   \n",
       "4  अधिकांश नेल्लिस सीमा के विपरीत, झील के आस-पास ...   \n",
       "\n",
       "                                            question       label  \\\n",
       "0         झील के सापेक्ष ग्रूम लेक रोड कहाँ जाती थी?  [378, 389]   \n",
       "1  किस प्रकार की सड़कें बड़े खेतों और पशु-फार्मों त...  [308, 316]   \n",
       "2               विमान के लिए परीक्षण पट्टी क्या बनी?  [237, 247]   \n",
       "3                 प्रारंभिक u-2 वितरण के साथ कौन था?  [330, 347]   \n",
       "4  प्रतिबंधित क्षेत्रों में भटकते पर सैन्य पायलटो...  [366, 378]   \n",
       "\n",
       "              answer  \n",
       "0        उत्तर पूर्व  \n",
       "1           डर्ट-रोड  \n",
       "2         झील की सतह  \n",
       "3  लॉकहीड विशेषज्ञों  \n",
       "4       अनुशासनात्मक  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadDataset:\n",
    "    \n",
    "    def __init__(self, tokenizer, context, answer, question, label, question_ids, max_len):\n",
    "        \n",
    "        self.context = context\n",
    "        self.answer = answer\n",
    "        self.question = question\n",
    "        self.tokenizer = tokenizer\n",
    "        self.question_ids = question_ids\n",
    "        self.max_len = max_len\n",
    "        self.label = label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.question)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        \n",
    "        context = self.context[item]\n",
    "        question = self.question[item]\n",
    "        answer = self.answer[item]\n",
    "        question_id = self.question_ids[item]\n",
    "        label = self.label[item]\n",
    "        long_example = False\n",
    "        ans_len = len(answer)\n",
    "        start_idx, end_idx = label[0], label[1]\n",
    "        \n",
    "#         for idx in (i for i, ch in enumerate(context) if ch == answer[0]):\n",
    "            \n",
    "#             if context[idx : idx+ans_len] == answer:\n",
    "#                 start_idx = idx\n",
    "#                 end_idx = idx + ans_len - 1\n",
    "#                 break\n",
    "        \n",
    "        char_targets = [0] * len(context)\n",
    "        if start_idx != -1 and end_idx != -1:\n",
    "            for i in range(start_idx, end_idx):\n",
    "                    char_targets[i] = 1\n",
    "                    \n",
    "        # [000000111111111000000]\n",
    "        \n",
    "        tokenized_ctx = self.tokenizer.encode(context)\n",
    "        context_tokens = tokenized_ctx.tokens\n",
    "        \n",
    "        #omit CLS and SEP\n",
    "        context_ids = tokenized_ctx.ids[1:-1]\n",
    "        \n",
    "        #omit CLS and SEP\n",
    "        context_offsets = tokenized_ctx.offsets[1:-1]\n",
    "        # [(0,0), (0,3), (4,6) ... ]\n",
    "        label_idx = []\n",
    "        for i, (offset1, offset2) in enumerate(context_offsets):\n",
    "            if sum(char_targets[offset1: offset2]) > 0:\n",
    "                label_idx.append(i)\n",
    "                \n",
    "        start_idx = label_idx[0]\n",
    "        end_idx = label_idx[-1]\n",
    "        \n",
    "        tokenized_qtn = self.tokenizer.encode(question)\n",
    "        question_tokens = tokenized_qtn.tokens\n",
    "        question_ids = tokenized_qtn.ids[1:-1]\n",
    "        question_offsets = tokenized_qtn.offsets[1:-1]\n",
    "        \n",
    "        CLS = [2]\n",
    "        SEP = [3]\n",
    "        \n",
    "        input_ids = CLS + question_ids + SEP + context_ids + SEP \n",
    "        token_type_ids = [0] * (len(question_ids) + 2) + [1] * (len(context_ids) + 1)\n",
    "        mask = [1] * len(token_type_ids)\n",
    "        start_idx += len(question_ids) + 2\n",
    "        end_idx += len(question_ids) + 2\n",
    "        offsets = [(0,0)] * 2 + question_offsets + context_offsets + [(0,0)]\n",
    "        \n",
    "        if len(input_ids) > self.max_len:\n",
    "            long_example = True\n",
    "            \n",
    "        \n",
    "        padding_len = self.max_len - len(input_ids)\n",
    "        if padding_len > 0:\n",
    "            input_ids = input_ids + ([0] * padding_len)\n",
    "            mask = mask + ([0] * padding_len)\n",
    "            token_type_ids = token_type_ids + ([0] * padding_len)\n",
    "            offsets = offsets + ([(0,0)] * padding_len)\n",
    "\n",
    "        \n",
    "        \n",
    "        return {\n",
    "            'input_ids':torch.tensor(input_ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'start_idx': torch.tensor(start_idx, dtype=torch.long),\n",
    "            'end_idx': torch.tensor(end_idx, dtype=torch.long),\n",
    "            'question_id':question_id,\n",
    "            'context':context,\n",
    "            'answer':answer,\n",
    "            'offsets':torch.tensor(offsets, dtype=torch.long),\n",
    "            'long_ex':long_example\n",
    "        }        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertWordPieceTokenizer('hi-lm-distilbert/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =  SquadDataset(tokenizer, \n",
    "                        df.context.values, \n",
    "                        df.answer.values, \n",
    "                        df.question.values,\n",
    "                        df.label.values,\n",
    "                        df.id.values, \n",
    "                        512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_long_examples(data):\n",
    "    \n",
    "    long_examples = []\n",
    "    for i in range(len(data)):\n",
    "        if dataset[i]['long_ex'] == True:\n",
    "            long_examples.append(i)\n",
    "    \n",
    "    return long_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_examples = filter_long_examples(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(long_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dataset(data):\n",
    "    error_indices = []\n",
    "    for i in range(len(data)):\n",
    "        try:\n",
    "            x = data[i]\n",
    "        except:\n",
    "            error_indices.append(i)\n",
    "\n",
    "    if len(error_indices) == 0:\n",
    "        print(\"Test passed succesfully\")\n",
    "    else:\n",
    "        print(f\"Error indices: {error_indices}\")\n",
    "        return error_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed succesfully\n"
     ]
    }
   ],
   "source": [
    "idx = test_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_answers(data, tokenizer):\n",
    "    \n",
    "    error_indices = []\n",
    "    for i,example in enumerate(data):\n",
    "        input_ids = example['input_ids'].tolist()\n",
    "        start_idx = int(example['start_idx'])\n",
    "        end_idx = int(example['end_idx'])\n",
    "        ground_truth = tokenizer.decode(tokenizer.encode(example['answer']).ids)\n",
    "        span = tokenizer.decode(input_ids[start_idx:end_idx+1])\n",
    "        \n",
    "        try:\n",
    "            assert span == ground_truth\n",
    "        except:\n",
    "            error_indices.append(i)\n",
    "    \n",
    "    if len(error_indices) == 0:\n",
    "        print(f\"Test passed successfully\")\n",
    "    else:\n",
    "        print(f\"Error indices: {error_indices}\")\n",
    "        return error_indices\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error indices: [13, 118, 185, 448, 509, 685, 712, 855, 1130, 1280, 1496, 1584, 1679, 1753, 1879, 2176, 2223, 2542, 2676, 2686, 2697, 2724, 2746, 2877, 3172, 3188, 3247, 3400, 3447, 3707, 3739, 3801, 3933, 4081, 4147, 4174, 4490, 4557, 4640, 4782, 4846, 4892, 5062, 5185, 5282, 5410, 5411, 5515, 5862, 5929, 6398]\n"
     ]
    }
   ],
   "source": [
    "error_indices = test_answers(dataset, tokenizer)\n",
    "remove_indices = set(error_indices + long_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dataset = []\n",
    "for i in range(len(dataset)):\n",
    "    if i not in remove_indices:\n",
    "        clean_dataset.append(dataset[i])\n",
    "    \n",
    "assert len(clean_dataset) == len(dataset) - len(remove_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = train_test_split(clean_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, 32)\n",
    "valid_loader = DataLoader(valid_dataset, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    pass\n",
    "\n",
    "for batch in valid_loader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4687, 1563)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "base_model = AutoModel.from_pretrained('hi-lm-distilbert/').to(device)\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertQA(nn.Module):\n",
    "    \n",
    "    def __init__(self, base_model):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.base_model = base_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.linear = nn.Linear(768, 2)\n",
    "    \n",
    "    def forward(self, input_ids, mask, token_type_ids):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            sequence_output = self.base_model(input_ids=input_ids, attention_mask=mask)[0]\n",
    "        # sequence_output = [bs, num_tokens, 768]\n",
    "        \n",
    "        linear_out = self.linear(self.dropout(sequence_output))\n",
    "        # [bs, num_tokens, 2]\n",
    "        \n",
    "        start_scores, end_scores = linear_out.split(1, dim=-1)\n",
    "        # start_scores = [bs, num_tokens, 1]\n",
    "        \n",
    "        start_scores = start_scores.squeeze(-1)\n",
    "        # [bs, num_tokens]\n",
    "        \n",
    "        end_scores = end_scores.squeeze(-1)\n",
    "        # [bs, num_tokens]\n",
    "        \n",
    "        return start_scores, end_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertQA(base_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    \n",
    "    for bi, batch in enumerate(loader):\n",
    "        \n",
    "        if bi % 30 == 0:\n",
    "            print(f\"Starting batch: {bi}\")\n",
    "            \n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        mask = batch['mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        start_idx = batch['start_idx'].to(device)\n",
    "        end_idx = batch['end_idx'].to(device)\n",
    "        \n",
    "        p1, p2 = model(input_ids, mask, token_type_ids)\n",
    "        \n",
    "        loss = F.cross_entropy(p1, start_idx) + F.cross_entropy(p2, end_idx)\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    \n",
    "    return train_loss/len(loader)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader):\n",
    "    \n",
    "    model.eval()\n",
    "    valid_loss = 0.\n",
    "    em, f1 = 0., 0.\n",
    "    predictions = {}\n",
    "    \n",
    "    for bi, batch in enumerate(loader):\n",
    "        \n",
    "        if bi % 30 == 0:\n",
    "            print(f\"Starting batch: {bi}\")\n",
    "            \n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        mask = batch['mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        start_idx = batch['start_idx'].to(device)\n",
    "        end_idx = batch['end_idx'].to(device)\n",
    "        context = batch['context']\n",
    "        question_id = batch['question_id']\n",
    "        offsets = batch['offsets']\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            p1, p2 = model(input_ids, mask, token_type_ids)\n",
    "\n",
    "            loss = F.cross_entropy(p1, start_idx) + F.cross_entropy(p2, end_idx)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "            \n",
    "            batch_size = p1.shape[0]\n",
    "            starts = torch.argmax(torch.softmax(p1, dim=1), dim=1)\n",
    "            ends = torch.argmax(torch.softmax(p2, dim=1), dim=1)\n",
    "\n",
    "#             batch_size, c_len = p1.size()\n",
    "#             ls = nn.LogSoftmax(dim=1)\n",
    "#             mask = (torch.ones(c_len, c_len) * float('-inf')).to(device).tril(-1).unsqueeze(0).expand(batch_size, -1, -1)\n",
    "#             score = (ls(p1).unsqueeze(2) + ls(p2).unsqueeze(1)) + mask\n",
    "#             score, s_idx = score.max(dim=1)\n",
    "#             score, e_idx = score.max(dim=1)\n",
    "#             s_idx = torch.gather(s_idx, 1, e_idx.view(-1, 1)).squeeze()\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                q_id = question_id[i]\n",
    "                start = starts[i]\n",
    "                end = ends[i]\n",
    "                pred = \"\"\n",
    "                \n",
    "                if end < start:\n",
    "                    end = start\n",
    "                    \n",
    "                for ix in range(start, end+1):\n",
    "                    pred += context[i][offsets[i][ix][0]:offsets[i][ix][1]]\n",
    "                    if (ix+1) < len(offsets[i]) and offsets[i][ix][1] < offsets[i][ix+1][0]:\n",
    "                        pred += \" \"\n",
    "                \n",
    "                predictions[q_id] = pred\n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "#             for i in range(batch_size):\n",
    "#                 q_id = question_id[i]\n",
    "#                 start = starts[i]\n",
    "#                 end = ends[i]\n",
    "#                 pred = input_ids[i][start: end+1]\n",
    "#                 pred = tokenizer.decode(pred.tolist())\n",
    "#                 predictions[q_id] = pred\n",
    "\n",
    "    em, f1 = get_metrics(predictions)\n",
    "    return valid_loss/len(loader), em, f1\n",
    "  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(predictions):\n",
    "    f1 = exact_match = total = 0\n",
    "    for i in range(len(valid_dataset)):\n",
    "        question_id = valid_dataset[i]['question_id']\n",
    "        ground_truth = valid_dataset[i]['answer']\n",
    "        prediction = predictions[question_id]\n",
    "        total += 1\n",
    "        f1 += f1_score(prediction, ground_truth)\n",
    "        exact_match += exact_match_score(prediction, ground_truth)\n",
    "\n",
    "    exact_match = 100.0 * exact_match / total\n",
    "    f1 = 100.0 * f1 / total\n",
    "\n",
    "    return exact_match, f1\n",
    "\n",
    "def normalize_answer(s):\n",
    "    \n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def normalize(text):\n",
    "        return tokenizer.decode(tokenizer.encode(text).ids)\n",
    "\n",
    "    return white_space_fix(remove_punc(normalize(s)))\n",
    "\n",
    "def f1_score(prediction, ground_truth):\n",
    "    prediction_tokens = normalize_answer(prediction).split()\n",
    "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "\n",
    "def exact_match_score(prediction, ground_truth):\n",
    "    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n",
    "\n",
    "import time\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Starting batch: 0\n",
      "Starting batch: 30\n",
      "Starting batch: 60\n",
      "Starting batch: 90\n",
      "Starting batch: 120\n",
      "Starting batch: 0\n",
      "Starting batch: 30\n",
      "Epoch train loss : 8.39178753872307| Time: 6m 49s\n",
      "Epoch valid loss: 7.829391440566705\n",
      "Epoch EM: 3.710812539987204\n",
      "Epoch F1: 10.26906456372915\n",
      "====================================================================================\n",
      "Epoch 2\n",
      "Starting batch: 0\n",
      "Starting batch: 30\n",
      "Starting batch: 60\n",
      "Starting batch: 90\n",
      "Starting batch: 120\n",
      "Starting batch: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "ems = []\n",
    "f1s = []\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_loader)\n",
    "    valid_loss, em, f1 = validate(model, valid_loader)\n",
    "    #scheduler.step(valid_loss)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    ems.append(em)\n",
    "    f1s.append(f1)\n",
    "    \n",
    "    print(f\"Epoch train loss : {train_loss}| Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(f\"Epoch valid loss: {valid_loss}\")\n",
    "    print(f\"Epoch EM: {em}\")\n",
    "    print(f\"Epoch F1: {f1}\")\n",
    "    print(\"====================================================================================\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.ones(c_len, c_len) * float('-inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = mask.tril(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [-inf, 0., 0.,  ..., 0., 0., 0.],\n",
       "        [-inf, -inf, 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [-inf, -inf, -inf,  ..., 0., 0., 0.],\n",
       "        [-inf, -inf, -inf,  ..., -inf, 0., 0.],\n",
       "        [-inf, -inf, -inf,  ..., -inf, -inf, 0.]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mask.shape)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.tril(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [4, 0, 0],\n",
       "        [7, 8, 0]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 100])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = mask.unsqueeze(0)\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = mask.expand(32,-1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 100])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = nn.LogSoftmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4137, -0.4797,  0.8668,  ...,  1.7687,  0.0290, -1.5110],\n",
       "        [-1.3654, -0.1342,  1.8637,  ...,  1.4508,  1.2209, -1.5940],\n",
       "        [ 0.3264,  1.9312,  1.4622,  ...,  2.5839,  0.6189, -1.5879],\n",
       "        ...,\n",
       "        [-1.2825,  0.6174, -0.7114,  ...,  0.2471,  0.6947, -0.6437],\n",
       "        [-1.0260,  0.6079,  0.3940,  ...,  0.1906, -0.6009, -1.7763],\n",
       "        [-0.7347,  1.3133,  0.2314,  ...,  0.3422,  0.3730,  1.1547]])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.7223, -5.6158, -4.2692,  ..., -3.3674, -5.1071, -6.6470],\n",
       "        [-6.4513, -5.2202, -3.2223,  ..., -3.6351, -3.8651, -6.6799],\n",
       "        [-4.7286, -3.1237, -3.5928,  ..., -2.4711, -4.4361, -6.6429],\n",
       "        ...,\n",
       "        [-6.3158, -4.4160, -5.7447,  ..., -4.7863, -4.3386, -5.6771],\n",
       "        [-5.9430, -4.3091, -4.5230,  ..., -4.7263, -5.5179, -6.6933],\n",
       "        [-5.7874, -3.7394, -4.8213,  ..., -4.7106, -4.6797, -3.8980]])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.7223],\n",
       "        [-5.6158],\n",
       "        [-4.2692],\n",
       "        [-6.0345],\n",
       "        [-5.4311],\n",
       "        [-7.2324],\n",
       "        [-6.2206],\n",
       "        [-4.5669],\n",
       "        [-4.3774],\n",
       "        [-3.2788],\n",
       "        [-4.6844],\n",
       "        [-5.6938],\n",
       "        [-6.2352],\n",
       "        [-4.5848],\n",
       "        [-5.0405],\n",
       "        [-6.6577],\n",
       "        [-5.2806],\n",
       "        [-5.0867],\n",
       "        [-4.6085],\n",
       "        [-5.9321],\n",
       "        [-3.8752],\n",
       "        [-5.7028],\n",
       "        [-3.6106],\n",
       "        [-4.8792],\n",
       "        [-4.4604],\n",
       "        [-4.1428],\n",
       "        [-4.2659],\n",
       "        [-5.4180],\n",
       "        [-4.8070],\n",
       "        [-4.3509],\n",
       "        [-4.3480],\n",
       "        [-3.6104],\n",
       "        [-4.9513],\n",
       "        [-5.4603],\n",
       "        [-7.0213],\n",
       "        [-3.8093],\n",
       "        [-6.5016],\n",
       "        [-6.0616],\n",
       "        [-3.3723],\n",
       "        [-5.3915],\n",
       "        [-7.1205],\n",
       "        [-4.6379],\n",
       "        [-4.5171],\n",
       "        [-5.8253],\n",
       "        [-2.6023],\n",
       "        [-5.2271],\n",
       "        [-4.6759],\n",
       "        [-4.7474],\n",
       "        [-5.8019],\n",
       "        [-5.3410],\n",
       "        [-4.4021],\n",
       "        [-3.1882],\n",
       "        [-5.0130],\n",
       "        [-5.2946],\n",
       "        [-5.4978],\n",
       "        [-4.7130],\n",
       "        [-4.0178],\n",
       "        [-5.9423],\n",
       "        [-4.6591],\n",
       "        [-4.7386],\n",
       "        [-5.5979],\n",
       "        [-5.0884],\n",
       "        [-6.3842],\n",
       "        [-4.4885],\n",
       "        [-3.8712],\n",
       "        [-4.2860],\n",
       "        [-5.6788],\n",
       "        [-4.9941],\n",
       "        [-3.4500],\n",
       "        [-5.6721],\n",
       "        [-5.5537],\n",
       "        [-4.7099],\n",
       "        [-4.3022],\n",
       "        [-4.7887],\n",
       "        [-7.3858],\n",
       "        [-4.3843],\n",
       "        [-5.5409],\n",
       "        [-5.6103],\n",
       "        [-3.9378],\n",
       "        [-6.0833],\n",
       "        [-4.5164],\n",
       "        [-5.9009],\n",
       "        [-3.7900],\n",
       "        [-3.7312],\n",
       "        [-5.1119],\n",
       "        [-4.7599],\n",
       "        [-4.9055],\n",
       "        [-4.3858],\n",
       "        [-6.1090],\n",
       "        [-6.7870],\n",
       "        [-6.4831],\n",
       "        [-4.3788],\n",
       "        [-5.3056],\n",
       "        [-5.4828],\n",
       "        [-6.9650],\n",
       "        [-4.8550],\n",
       "        [-5.1619],\n",
       "        [-3.3674],\n",
       "        [-5.1071],\n",
       "        [-6.6470]])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = ls(p1).unsqueeze(2)\n",
    "l1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.8925, -5.8321, -5.6961, -4.1644, -4.0735, -4.3292, -6.7989, -5.9053,\n",
       "         -4.4028, -5.0780, -2.4458, -6.1392, -6.3915, -6.0832, -5.2859, -5.1156,\n",
       "         -5.8976, -5.4570, -4.6064, -4.3223, -4.2313, -3.5619, -3.5639, -4.9775,\n",
       "         -5.5472, -6.9181, -4.2203, -3.5374, -5.7007, -5.3400, -3.4137, -4.0631,\n",
       "         -5.1530, -4.7224, -3.1887, -4.2997, -6.6982, -4.8285, -4.8412, -4.1327,\n",
       "         -6.8859, -4.8507, -3.6329, -3.7325, -5.1929, -5.6284, -3.8776, -6.4303,\n",
       "         -4.9868, -4.9549, -5.5869, -6.9362, -6.2101, -4.9045, -4.6439, -5.1715,\n",
       "         -6.2859, -5.4918, -3.2712, -4.2374, -4.4704, -4.9609, -4.7038, -6.3677,\n",
       "         -3.2878, -5.8089, -5.3367, -5.0135, -4.2300, -4.8668, -5.5809, -7.1074,\n",
       "         -5.3295, -4.5600, -6.8262, -5.3395, -4.9323, -4.1471, -3.8173, -5.0625,\n",
       "         -5.3152, -5.3000, -3.9520, -6.1997, -5.9521, -6.6265, -5.9507, -4.8792,\n",
       "         -5.0215, -4.5036, -5.6782, -4.1145, -6.9351, -6.6818, -4.3470, -7.1892,\n",
       "         -3.9099, -6.9267, -5.1517, -5.8537]])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = ls(p2).unsqueeze(1)\n",
    "l2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-10.6149, -10.5544, -10.4184,  ..., -11.6490,  -9.8740, -10.5760],\n",
       "        [-11.5083, -11.4478, -11.3118,  ..., -12.5424, -10.7674, -11.4694],\n",
       "        [-10.1618, -10.1013,  -9.9653,  ..., -11.1959,  -9.4209, -10.1229],\n",
       "        ...,\n",
       "        [ -9.2599,  -9.1994,  -9.0634,  ..., -10.2940,  -8.5190,  -9.2210],\n",
       "        [-10.9996, -10.9391, -10.8031,  ..., -12.0337, -10.2587, -10.9607],\n",
       "        [-12.5395, -12.4791, -12.3431,  ..., -13.5737, -11.7987, -12.5007]])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(l1 + l2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = ls(p1).unsqueeze(2) + ls(p2).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 100])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = score + mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-10.6149, -10.5544, -10.4184,  ..., -11.6490,  -9.8740, -10.5760],\n",
       "         [    -inf, -11.4478, -11.3118,  ..., -12.5424, -10.7674, -11.4694],\n",
       "         [    -inf,     -inf,  -9.9653,  ..., -11.1959,  -9.4209, -10.1229],\n",
       "         ...,\n",
       "         [    -inf,     -inf,     -inf,  ..., -10.2940,  -8.5190,  -9.2210],\n",
       "         [    -inf,     -inf,     -inf,  ...,     -inf, -10.2587, -10.9607],\n",
       "         [    -inf,     -inf,     -inf,  ...,     -inf,     -inf, -12.5007]],\n",
       "\n",
       "        [[-10.9911, -10.9528, -10.6235,  ..., -12.9481, -10.5561, -13.5723],\n",
       "         [    -inf,  -9.7217,  -9.3923,  ..., -11.7170,  -9.3249, -12.3412],\n",
       "         [    -inf,     -inf,  -7.3944,  ...,  -9.7191,  -7.3270, -10.3433],\n",
       "         ...,\n",
       "         [    -inf,     -inf,     -inf,  ..., -10.1319,  -7.7399, -10.7561],\n",
       "         [    -inf,     -inf,     -inf,  ...,     -inf,  -7.9698, -10.9861],\n",
       "         [    -inf,     -inf,     -inf,  ...,     -inf,     -inf, -13.8009]],\n",
       "\n",
       "        [[-10.7144,  -9.1789,  -8.9693,  ..., -10.0038,  -8.6048,  -8.0766],\n",
       "         [    -inf,  -7.5740,  -7.3644,  ...,  -8.3990,  -6.9999,  -6.4718],\n",
       "         [    -inf,     -inf,  -7.8335,  ...,  -8.8680,  -7.4689,  -6.9408],\n",
       "         ...,\n",
       "         [    -inf,     -inf,     -inf,  ...,  -7.7463,  -6.3472,  -5.8191],\n",
       "         [    -inf,     -inf,     -inf,  ...,     -inf,  -8.3123,  -7.7841],\n",
       "         [    -inf,     -inf,     -inf,  ...,     -inf,     -inf,  -9.9909]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-11.5930, -10.4868, -12.2158,  ..., -12.3320, -12.0756, -11.3820],\n",
       "         [    -inf,  -8.5869, -10.3159,  ..., -10.4321, -10.1758,  -9.4822],\n",
       "         [    -inf,     -inf, -11.6446,  ..., -11.7609, -11.5045, -10.8109],\n",
       "         ...,\n",
       "         [    -inf,     -inf,     -inf,  ..., -10.8024, -10.5460,  -9.8524],\n",
       "         [    -inf,     -inf,     -inf,  ...,     -inf, -10.0984,  -9.4048],\n",
       "         [    -inf,     -inf,     -inf,  ...,     -inf,     -inf, -10.7433]],\n",
       "\n",
       "        [[-11.5702, -11.6424, -10.8750,  ..., -10.1501, -11.1069, -11.3991],\n",
       "         [    -inf, -10.0084,  -9.2411,  ...,  -8.5162,  -9.4729,  -9.7652],\n",
       "         [    -inf,     -inf,  -9.4550,  ...,  -8.7301,  -9.6868,  -9.9791],\n",
       "         ...,\n",
       "         [    -inf,     -inf,     -inf,  ...,  -8.9335,  -9.8902, -10.1825],\n",
       "         [    -inf,     -inf,     -inf,  ...,     -inf, -10.6818, -10.9740],\n",
       "         [    -inf,     -inf,     -inf,  ...,     -inf,     -inf, -12.1494]],\n",
       "\n",
       "        [[-12.1434, -10.9043,  -8.9835,  ..., -10.7619,  -9.1635,  -9.3675],\n",
       "         [    -inf,  -8.8563,  -6.9355,  ...,  -8.7139,  -7.1155,  -7.3195],\n",
       "         [    -inf,     -inf,  -8.0174,  ...,  -9.7958,  -8.1974,  -8.4014],\n",
       "         ...,\n",
       "         [    -inf,     -inf,     -inf,  ...,  -9.6850,  -8.0866,  -8.2906],\n",
       "         [    -inf,     -inf,     -inf,  ...,     -inf,  -8.0558,  -8.2598],\n",
       "         [    -inf,     -inf,     -inf,  ...,     -inf,     -inf,  -7.4781]]])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, s_idx = score.max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-10.6149, -10.5544,  -9.9653,  ...,  -9.5290,  -7.7540,  -8.4560],\n",
       "        [-10.9911,  -9.7217,  -7.3944,  ...,  -9.3226,  -6.9306,  -9.9468],\n",
       "        [-10.7144,  -7.5740,  -7.3644,  ...,  -7.7463,  -6.3472,  -5.8191],\n",
       "        ...,\n",
       "        [-11.5930,  -8.5869, -10.3159,  ...,  -8.6843,  -8.4279,  -7.7343],\n",
       "        [-11.5702, -10.0084,  -9.2411,  ...,  -6.4838,  -7.4405,  -7.7328],\n",
       "        [-12.1434,  -8.8563,  -6.9355,  ...,  -7.7213,  -6.1229,  -6.3269]])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, e_idx = score.max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1602, -0.3537, -0.1346],\n",
       "         [-0.0267,  0.9523,  0.2527],\n",
       "         [-0.0346, -0.8539,  0.8453]],\n",
       "\n",
       "        [[-1.3406, -1.2280, -0.0061],\n",
       "         [-1.0539,  1.2168, -0.8714],\n",
       "         [-1.4040, -0.5714, -0.9305]]])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(values=tensor([[-1.1602, -0.3537, -0.0061],\n",
       "        [-0.0267,  1.2168,  0.2527],\n",
       "        [-0.0346, -0.5714,  0.8453]]), indices=tensor([[0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0]]))"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.max(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(values=tensor([[-0.0267,  0.9523,  0.8453],\n",
       "        [-1.0539,  1.2168, -0.0061]]), indices=tensor([[1, 1, 2],\n",
       "        [1, 1, 0]]))"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(values=tensor([[-0.1346,  0.9523,  0.8453],\n",
       "        [-0.0061,  1.2168, -0.5714]]), indices=tensor([[2, 1, 2],\n",
       "        [2, 1, 1]]))"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.max(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "a , s = a.max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0267,  0.9523,  0.8453],\n",
       "        [-1.0539,  1.2168, -0.0061]])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor([[1],[2],[3],[4]])\n",
    "n = torch.tensor([[1,2,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = m + n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1659, -1.7538, -1.8445],\n",
       "        [-1.2636, -0.9122, -0.0057]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0057)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a0, s = a.max(dim=0)\n",
    "a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-c27e1ce758c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "a1, e = a.max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.7538, -0.0057])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
